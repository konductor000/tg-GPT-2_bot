{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPY0CaFmZkgD2IEt/PbnYVS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/konductor000/tg-GPT-2_bot/blob/main/bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b81cw5pyaxg1",
        "outputId": "ee682fa7-2ace-4c62-9f11-b87aed3851a7"
      },
      "source": [
        "!pip3 install tensorflow-gpu==1.12.0\n",
        "!pip3 install pyTelegramBotAPI\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==1.12.0 in /usr/local/lib/python3.6/dist-packages (1.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.32.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (3.12.4)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\r\u001b[K     |██████▌                         | 10kB 26.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20kB 32.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 30kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 40kB 21.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (0.10.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (0.36.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.19.5)\n",
            "Collecting tensorboard<1.13.0,>=1.12.0\n",
            "  Using cached https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.12.0) (53.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.12.0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu==1.12.0) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu==1.12.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow-gpu==1.12.0) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow-gpu==1.12.0) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow-gpu==1.12.0) (3.7.4.3)\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorboard~=2.4, but you'll have tensorboard 1.12.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, tensorboard\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.12.2\n",
            "Requirement already satisfied: pyTelegramBotAPI in /usr/local/lib/python3.6/dist-packages (3.7.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pyTelegramBotAPI) (2.21.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pyTelegramBotAPI) (2020.12.5)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pyTelegramBotAPI) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pyTelegramBotAPI) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pyTelegramBotAPI) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sw9O9ORbLDO",
        "outputId": "b7f2a0ae-0047-418d-dc91-06923e777b0c"
      },
      "source": [
        "# Use Tensorflow 1\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "# Select GPT-2 model: 117M, 124M, 355M, 774M, 1558M\n",
        "\n",
        "model_name = '1558M'     # '117M' - smallest model. Set '1558M' for biggest 1.5B model\n",
        "\n",
        "!git clone https://github.com/openai/gpt-2\n",
        "\n",
        "%cd gpt-2\n",
        "\n",
        "!pip3 install -r requirements.txt\n",
        "\n",
        "# Download GPT-2 (selected model, for example 117M)\n",
        "!python3 download_model.py $model_name\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "fatal: destination path 'gpt-2' already exists and is not an empty directory.\n",
            "/content/gpt-2\n",
            "Requirement already satisfied: fire>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.4.0)\n",
            "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (2017.4.5)\n",
            "Requirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n",
            "Requirement already satisfied: tqdm==4.31.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.31.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2020.12.5)\n",
            "Fetching checkpoint: 1.00kit [00:00, 1.09Mit/s]                                                     \n",
            "Fetching encoder.json: 1.04Mit [00:00, 4.62Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 1.18Mit/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 6.23Git [03:58, 26.1Mit/s]                                 \n",
            "Fetching model.ckpt.index: 21.0kit [00:00, 727kit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.84Mit [00:00, 4.69Mit/s]                                                \n",
            "Fetching vocab.bpe: 457kit [00:00, 3.20Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu9PvOmNbVJh",
        "outputId": "c9f8feb7-2d07-42d1-be20-d3c42c7e7ed1"
      },
      "source": [
        "%cd src"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpt-2/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIFyD0SWbVmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81db95a3-77dc-4bf6-925e-c27556b11a72"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import model, sample, encoder\n",
        "import telebot\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9CAXySiwcHZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq5x8MhQbVo3"
      },
      "source": [
        "class GPT():\n",
        "\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      model_name,\n",
        "      seed,\n",
        "      length,\n",
        "      temperature,\n",
        "      top_k,\n",
        "      models_dir\n",
        "  ):\n",
        "      models_dir = os.path.expanduser(os.path.expandvars(models_dir))\n",
        "\n",
        "\n",
        "      self.enc = encoder.get_encoder(model_name, models_dir)\n",
        "      hparams = model.default_hparams()\n",
        "      with open(os.path.join(models_dir, model_name, 'hparams.json')) as f:\n",
        "          hparams.override_from_dict(json.load(f))\n",
        "\n",
        "      if length is None:\n",
        "          length = hparams.n_ctx // 2\n",
        "      elif length > hparams.n_ctx:\n",
        "          raise ValueError(\"Can't get samples longer than window size: %s\" % hparams.n_ctx)\n",
        "\n",
        "      g = tf.Graph() \n",
        "      with g.as_default():\n",
        "      \n",
        "        self.context = tf.placeholder(tf.int32, [1, None])\n",
        "        np.random.seed(seed)\n",
        "        tf.set_random_seed(seed)\n",
        "        self.output = sample.sample_sequence(\n",
        "            hparams=hparams, length=length,\n",
        "            context=self.context,\n",
        "            batch_size=1,\n",
        "            temperature=temperature, top_k=top_k\n",
        "        )\n",
        "\n",
        "        saver = tf.train.Saver()\n",
        "        ckpt = tf.train.latest_checkpoint(os.path.join(models_dir, model_name))\n",
        "      \n",
        "      self.sess = tf.compat.v1.Session(graph=g) \n",
        "      saver.restore(self.sess, ckpt)\n",
        "\n",
        "\n",
        "  def print_message(self, raw_text):\n",
        "    context_tokens = self.enc.encode(raw_text)\n",
        "    \n",
        "    out = self.sess.run(self.output, feed_dict={\n",
        "        self.context: [context_tokens for _ in range(1)]\n",
        "    })[:, len(context_tokens):]\n",
        "    for i in range(1):\n",
        "        text = self.enc.decode(out[i])\n",
        "        return text\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndPF4jxPyNu3",
        "outputId": "1ce595c5-6400-4e36-fda4-76ccde438161"
      },
      "source": [
        "gpt = GPT(\r\n",
        "    model_name,\r\n",
        "    None,\r\n",
        "    100,\r\n",
        "    1,\r\n",
        "    40,\r\n",
        "    '/content/gpt-2/models'\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/gpt-2/models/1558M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/gpt-2/models/1558M/model.ckpt\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG4SFc2FlcDc"
      },
      "source": [
        "\n",
        "\n",
        "bot = telebot.TeleBot(\"1602318304:AAG0YvOX8MhX7nEWqmJjyVpq5EdQhgTnVLg\")\n",
        "\n",
        "@bot.message_handler(commands=['start'])\n",
        "def send_welcome(message):\n",
        "    bot.reply_to(message, f'Hi, {message.from_user.first_name}! I am a GPT-2 bot. Enter some text and you will receive a continue of your text.')\n",
        "\n",
        "\n",
        "@bot.message_handler(content_types=['text'])\n",
        "def send_text(message):\n",
        "    text = message.text\n",
        "    bot.send_message(message.chat.id, text + gpt.print_message(text))\n",
        "\n",
        "bot.polling(none_stop=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}